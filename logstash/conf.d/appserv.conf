input {
   beats {
      type => beats
      port => 5044
   }
}

filter {

  # Drop empty log lines
  if [message] == "" {
    drop { }
  }

  # App Server APPSRV Logs
  if [log_source] == "appsrv_log" {
    grok {
      patterns_dir => "/etc/logstash/conf.d/patterns"
      match => { "message" => "%{APPSRV_LOG}"}
      add_field => { "log_name" => "App Server Log" }
      add_field => { "server type" => "appserv" }
      remove_tag => ["_grokparsefailure"]
    }

    if [log_message] =~ "authentication" {
      grok {
        patterns_dir => "/etc/logstash/conf.d/patterns"
        match => { "log_message" => "%{LOGIN_DATA}"}
        remove_tag => ["_grokparsefailure"]
        add_tag => ["login"]
      }
    }

    if [log_message] =~ "SQL" {
      grok {
        patterns_dir => "/etc/logstash/conf.d/patterns"
        match => { "log_message" => "%{BAD_SQL}"}
        remove_tag => ["_grokparsefailure"]
        add_tag => ["sql_error"]
      }
    }

    if [log_message] =~ "Executing component" {
      grok {
        patterns_dir => "/etc/logstash/conf.d/patterns"
        match => { "log_message" => "%{EXEC_COMP}" }
        add_tag => ["comp_exec"]
      }

      # Create new entry that combines component name with durations
      aggregate {
        task_id => "%{vm}%{pid}%{service_request}"
        code => "map['componentName'] = event.get('componentName')"
        map_action => "create"
      }
    }

    if [log_message] =~ "elapsed time=" {
      grok {
        patterns_dir => "/etc/logstash/conf.d/patterns"
        match => { "log_message" => "%{SERVICE_DUR}" }
        add_tag => ["comp_duration"]
      }

      aggregate {
        task_id => "%{vm}%{pid}%{service_request}"
        code => "event.set('componentName', map['componentName'])"
        map_action => "update"
        end_of_task => true
        timeout => 600
        push_map_as_event_on_timeout => true
        add_tag => ["duration"]
      }
    }

    if [message] =~ "PSPAL" {
      grok {
        patterns_dir => "/etc/logstash/conf.d/patterns"
        match => { "message" => "%{CRASH}"}
        remove_tag => ["_grokparsefailure"]
        add_tag => ["crash"]
      }
    }

    date {
      match => ["datetime", "MM/dd/YY HH:mm:ss", "MM/dd/YY H:mm:ss", "M/dd/YY HH:mm:ss", "M/dd/YY H:mm:ss",  "ISO8601"]
      remove_field => [ "datetime" ]
    }

    mutate {
      convert => {"duration" => "float"}
    }

  }

  if [useragent] {
    useragent {
      source=> "useragent"
      target => "agent"
    }
  }
}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    manage_template => false
    index => "%{[@metadata][beat]}-%{+YYYY.MM.dd}"
  }
}
