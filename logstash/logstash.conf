input {
  beats {
    type => beats
    port => 5044
    id   => "beats-1"
  }
}
filter {
  # Drop empty log lines
  if [message] == "" {
    drop {
      id => "drop-2"
    }
  }

  # Web Server Access Logs
  if [document_type] == "access_log" {
    # drop comment lines
    if ([message] =~ /^#/) {
      drop {
        id => "drop-3"
      }
    }

    # WL Extended Log Format
    grok {
      patterns_dir => "/usr/share/logstash/pipeline/patterns"
      match => {
        "message" => "%{WL_IO_EXTENDED}"
      }
      add_field => {
        "log" => "Access Log"
      }
      add_field => {
        "server type" => "webserv"
      }
      remove_tag => [
        "_grokparsefailure"
      ]
      id => "grok-4"
    }

    if [tag] == "_grokparsefailure" {
      grok {
        match => {
          "message" => "%{COMMONAPACHELOG}"
        }
        add_field => {
          "log" => "Access Log"
        }
        add_field => {
          "server type" => "webserv"
        }
        remove_tag => [
          "_grokparsefailure"
        ]
        id => "grok-5"
      }
    }

    if [request] {
      grok {
        patterns_dir => "/usr/share/logstash/pipeline/patterns"
        match => {
          "request" => "%{PS_URI_REQUEST}"
        }
        add_tag => [
          "PIA_reqeust"
        ]
        remove_tag => [
          "_grokparsefailure"
        ]
        id => "grok-6"
      }
    }

    mutate {
      convert => {
        "duration" => "float"
      }
      convert => {
        "bytes" => "integer"
      }
      id => "mutate-7"
    }

    kv {
      source => "request"
      target => "parameters"
      field_split => "&?"
      include_keys => [
        "SEARCH_GROUP",
        "PAGE"
      ]
      id => "kv-8"
    }

    # Fix for tab-delimted time field... build a new field in a friendly format
    mutate {
      add_field => {
        "datetime" => "%{year}-%{month}-%{day} %{time}"
      }
      id => "mutate-9"
    }

    date {
      match => [
        "datetime",
        "yyyy-MM-dd HH:mm:ss"
      ]
      remove_field => [
        "datetime"
      ]
      id => "date-10"
    }
  }

  # App Server APPSRV Logs
  if [document_type] == "appsrv_log" {
    grok {
      patterns_dir => "/usr/share/logstash/pipeline/patterns"
      match => {
        "message" => "%{APPSRV_LOG}"
      }
      add_field => {
        "log" => "App Server Log"
      }
      add_field => {
        "server type" => "appserv"
      }
      remove_tag => [
        "_grokparsefailure"
      ]
      id => "grok-11"
    }

    if [log_message] =~ "authentication" {
      grok {
        patterns_dir => "/usr/share/logstash/pipeline/patterns"
        match => {
          "log_message" => "%{LOGIN_DATA}"
        }
        remove_tag => [
          "_grokparsefailure"
        ]
        add_tag => [
          "login"
        ]
        id => "grok-12"
      }
    }

    if [log_message] =~ "SQL" {
      grok {
        patterns_dir => "/usr/share/logstash/pipeline/patterns"
        match => {
          "log_message" => "%{BAD_SQL}"
        }
        remove_tag => [
          "_grokparsefailure"
        ]
        add_tag => [
          "sql_error"
        ]
        id => "grok-13"
      }
    }

    if [log_message] =~ "Executing component" {
      grok {
        patterns_dir => "/usr/share/logstash/pipeline/patterns"
        match => {
          "log_message" => "%{EXEC_COMP}"
        }
        add_tag => [
          "comp_exec"
        ]
        id => "grok-14"
      }

      # Create new entry that combines component name with durations
      aggregate {
        task_id => "%{vm}%{pid}%{service_request}"
        code => "map['componentName'] = event.get('componentName')"
        map_action => "create"
        id => "aggregate-15"
      }
    }

    if [log_message] =~ "elapsed time=" {
      grok {
        patterns_dir => "/usr/share/logstash/pipeline/patterns"
        match => {
          "log_message" => "%{SERVICE_DUR}"
        }
        add_tag => [
          "comp_duration"
        ]
        id => "grok-16"
      }

      aggregate {
        task_id => "%{vm}%{pid}%{service_request}"
        code => "event.set('componentName', map['componentName'])"
        map_action => "update"
        end_of_task => true
        timeout => 600
        push_map_as_event_on_timeout => true
        add_tag => [
          "duration"
        ]
        id => "aggregate-17"
      }
    }

    if [message] =~ "PSPAL" {
      grok {
        patterns_dir => "/usr/share/logstash/pipeline/patterns"
        match => {
          "message" => "%{CRASH}"
        }
        remove_tag => [
          "_grokparsefailure"
        ]
        add_tag => [
          "crash"
        ]
        id => "grok-18"
      }
    }

    date {
      match => [
        "datetime",
        "MM/dd/YY HH:mm:ss",
        "MM/dd/YY H:mm:ss",
        "M/dd/YY HH:mm:ss",
        "M/dd/YY H:mm:ss",
        "ISO8601"
      ]
      remove_field => [
        "datetime"
      ]
      id => "date-19"
    }

    mutate {
      convert => {
        "duration" => "float"
      }
      id => "mutate-20"
    }
  }

  if [useragent] {
    useragent {
      source => "useragent"
      target => "agent"
      id => "useragent-21"
    }
  }

  if [document_type] == "appsrv_queue_log" {
    grok {
      patterns_dir => "/usr/share/logstash/pipeline/patterns"
      match => {
        "message" => "%{APP_QUEUE}"
      }
      add_field => {
        "log" => "App Server Queue"
      }
      add_field => {
        "server_type" => "appserver"
      }
      id => "grok-22"
    }

    mutate {
      convert => {
        "active_processes" => "integer"
      }
      convert => {
        "queued_requests" => "integer"
      }
      id => "mutate-23"
    }

    date {
      match => [
        "datetime",
        "ISO8601"
      ]
      remove_field => [
        "datetime"
      ]
      id => "date-24"
    }
  }

  if [document_type] == "appsrv_request_log" {
    grok {
      patterns_dir => "/usr/share/logstash/pipeline/patterns"
      match => {
        "message" => "%{APP_REQUEST}"
      }
      add_field => {
        "log" => "App Server Request"
      }
      add_field => {
        "server_type" => "appserver"
      }
      id => "grok-25"
    }

    mutate {
      convert => {
        "id" => "integer"
      }
      convert => {
        "requests_done" => "integer"
      }
      convert => {
        "load_done" => "integer"
      }
      id => "mutate-26"
    }

    date {
      match => [
        "datetime",
        "ISO8601"
      ]
      remove_field => [
        "datetime"
      ]
      id => "date-27"
    }
  }
}
output {
  opensearch {
    hosts           => ["https://opensearch-node1:9200"]
    user            => "admin"
    password        => "admin"
    index           => "pslogs-%{+YYYY-MM-dd}"
    action          => create
    manage_template => false
    ssl             => true
    ssl_certificate_verification => false
    id              => "opensearch-output"
  }

  # stdout {
  # codec => "json"
  # }
}